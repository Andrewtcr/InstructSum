{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d4e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict, Dataset\n",
    "import numpy as np\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af178b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andrew/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45444969",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b4ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 1024\n",
    "max_target = 128\n",
    "# model_checkpoint = \"./bart-large-cnn-finetuned/checkpoint-10650/\"\n",
    "model_checkpoint = \"../BART-SFT/checkpoint-150/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af269be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_from_disk(\"../data/hf_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a278a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f35143",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f06970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    # get all the articles, prepend each with \"bias;\"\n",
    "    inputs = [\n",
    "        f\"{bias}; {article}\"\n",
    "        for bias, article in zip(examples[\"summary_bias\"], examples[\"article\"])\n",
    "    ]\n",
    "    # tokenize the inputs\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=max_input, padding=\"max_length\", truncation=True\n",
    "    )\n",
    "\n",
    "    # tokenize the summaries\n",
    "    targets = tokenizer(\n",
    "        examples[\"summary\"],\n",
    "        max_length=max_target,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    # set labels\n",
    "    model_inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    # return the tokenized data\n",
    "    # input_ids, attention_mask and labels\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\n",
    "        \"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds\n",
    "    ]\n",
    "    decoded_labels = [\n",
    "        \"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels\n",
    "    ]\n",
    "\n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        use_stemmer=True,\n",
    "        use_aggregator=True,\n",
    "    )\n",
    "    # Extract a few results\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eed69e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd38736c20f43c9a52eaa7a0c23d1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac7883fb187444aafcbee701127a3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/542 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362e607187df4ed586123257f81695e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/602 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = raw_datasets.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74796aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/andrew/InstructSum/models/test.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model_name \u001b[39m=\u001b[39m model_checkpoint\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m args \u001b[39m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBART-SFT\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msteps\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     eval_steps\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     warmup_steps\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m2e-5\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     per_device_eval_batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     log_level\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minfo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     logging_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./log\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     logging_first_step\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     logging_steps\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     save_total_limit\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     save_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msteps\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     save_steps\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     load_best_model_at_end\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     predict_with_generate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     fp16\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m data_collator \u001b[39m=\u001b[39m DataCollatorForSeq2Seq(tokenizer, model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     model,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Binstance-2.northamerica-northeast1-c.instructsum/home/andrew/InstructSum/models/test.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m )\n",
      "File \u001b[0;32m<string>:122\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, neftune_noise_alpha, sortish_sampler, predict_with_generate, generation_max_length, generation_num_beams, generation_config)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/dl/lib/python3.11/site-packages/transformers/training_args.py:1448\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1439\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1441\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16_full_eval)\n\u001b[1;32m   1447\u001b[0m ):\n\u001b[0;32m-> 1448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1449\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1450\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1451\u001b[0m     )\n\u001b[1;32m   1453\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1454\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1455\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16_full_eval)\n\u001b[1;32m   1463\u001b[0m ):\n\u001b[1;32m   1464\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1465\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBF16 Mixed precision training with AMP (`--bf16`) and BF16 half precision evaluation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1466\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (`--bf16_full_eval`) can only be used on CUDA, XPU (with IPEX), NPU or CPU/TPU/NeuronCore devices.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1467\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX)."
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"BART-SFT\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=150,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    log_level=\"info\",\n",
    "    logging_dir=\"./log\",\n",
    "    logging_first_step=True,\n",
    "    logging_steps=5,\n",
    "    save_total_limit=3,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=150,\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=25,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1d5d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "matches = defaultdict(list)\n",
    "for item in tokenized_data[\"test\"]:\n",
    "    matches[f\"{item['id']}_{item['article_bias']}\"].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7965f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "for key, val in matches.items():\n",
    "    if len(val) == 3:\n",
    "        keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "468d6722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5010_center',\n",
       " '5010_left',\n",
       " '5010_right',\n",
       " '5037_center',\n",
       " '5037_left',\n",
       " '5037_right',\n",
       " '612_center',\n",
       " '612_left',\n",
       " '612_right',\n",
       " '4972_center',\n",
       " '4972_left',\n",
       " '4972_right',\n",
       " '4661_center',\n",
       " '4661_left',\n",
       " '4661_right',\n",
       " '4892_center',\n",
       " '4892_left',\n",
       " '4892_right',\n",
       " '1866_center',\n",
       " '1866_left',\n",
       " '1866_right',\n",
       " '5012_center',\n",
       " '5012_left',\n",
       " '5012_right',\n",
       " '4465_center',\n",
       " '4465_left',\n",
       " '4465_right',\n",
       " '4186_center',\n",
       " '4186_left',\n",
       " '4186_right',\n",
       " '3678_center',\n",
       " '3678_left',\n",
       " '3678_right',\n",
       " '3242_center',\n",
       " '3242_left',\n",
       " '3242_right',\n",
       " '3234_center',\n",
       " '3234_left',\n",
       " '3234_right',\n",
       " '3711_center',\n",
       " '3711_left',\n",
       " '3711_right',\n",
       " '4845_center',\n",
       " '4845_left',\n",
       " '4845_right',\n",
       " '4217_center',\n",
       " '4217_left',\n",
       " '4217_right',\n",
       " '319_center',\n",
       " '319_left',\n",
       " '319_right',\n",
       " '5020_center',\n",
       " '5020_left',\n",
       " '5020_right',\n",
       " '4162_center',\n",
       " '4162_left',\n",
       " '4162_right',\n",
       " '3927_center',\n",
       " '3927_left',\n",
       " '3927_right',\n",
       " '2231_center',\n",
       " '2231_left',\n",
       " '2231_right',\n",
       " '4305_center',\n",
       " '4305_left',\n",
       " '4305_right',\n",
       " '5219_center',\n",
       " '5219_left',\n",
       " '5219_right',\n",
       " '4850_center',\n",
       " '4850_left',\n",
       " '4850_right',\n",
       " '3984_center',\n",
       " '3984_left',\n",
       " '3984_right',\n",
       " '5100_center',\n",
       " '5100_left',\n",
       " '5100_right',\n",
       " '3959_center',\n",
       " '3959_left',\n",
       " '3959_right',\n",
       " '4218_center',\n",
       " '4218_left',\n",
       " '4218_right',\n",
       " '3865_center',\n",
       " '3865_left',\n",
       " '3865_right',\n",
       " '4440_center',\n",
       " '4440_left',\n",
       " '4440_right',\n",
       " '4631_center',\n",
       " '4631_left',\n",
       " '4631_right',\n",
       " '3566_center',\n",
       " '3566_left',\n",
       " '3566_right',\n",
       " '573_center',\n",
       " '573_left',\n",
       " '573_right',\n",
       " '2690_center',\n",
       " '2690_left',\n",
       " '2690_right',\n",
       " '5099_center',\n",
       " '5099_left',\n",
       " '5099_right',\n",
       " '2158_center',\n",
       " '2158_left',\n",
       " '2158_right',\n",
       " '4122_center',\n",
       " '4122_left',\n",
       " '4122_right',\n",
       " '3091_center',\n",
       " '3091_left',\n",
       " '3091_right',\n",
       " '2560_center',\n",
       " '2560_left',\n",
       " '2560_right',\n",
       " '4577_center',\n",
       " '4577_left',\n",
       " '4577_right',\n",
       " '1135_center',\n",
       " '1135_left',\n",
       " '1135_right',\n",
       " '3148_center',\n",
       " '3148_left',\n",
       " '3148_right',\n",
       " '394_center',\n",
       " '394_left',\n",
       " '394_right',\n",
       " '3912_center',\n",
       " '3912_left',\n",
       " '3912_right',\n",
       " '4007_center',\n",
       " '4007_left',\n",
       " '4007_right',\n",
       " '4279_center',\n",
       " '4279_left',\n",
       " '4279_right',\n",
       " '3563_center',\n",
       " '3563_left',\n",
       " '3563_right',\n",
       " '2260_center',\n",
       " '2260_left',\n",
       " '2260_right',\n",
       " '4965_center',\n",
       " '4965_left',\n",
       " '4965_right',\n",
       " '2259_center',\n",
       " '2259_left',\n",
       " '2259_right',\n",
       " '4136_center',\n",
       " '4136_left',\n",
       " '4136_right',\n",
       " '4717_center',\n",
       " '4717_left',\n",
       " '4717_right',\n",
       " '3736_center',\n",
       " '3736_left',\n",
       " '3736_right',\n",
       " '3693_center',\n",
       " '3693_left',\n",
       " '3693_right',\n",
       " '2918_center',\n",
       " '2918_left',\n",
       " '2918_right',\n",
       " '4957_center',\n",
       " '4957_left',\n",
       " '4957_right']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47758f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['center', 'left', 'right']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t['article_bias'] for t in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "031b04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tokenized_data[\"test\"].select([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ad11bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: article, summary_bias, summary, id, article_bias. If article, summary_bias, summary, id, article_bias are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 4\n",
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds2 = trainer.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd354014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 2.01328444480896,\n",
       " 'test_rouge1': 26.0676,\n",
       " 'test_rouge2': 5.2797,\n",
       " 'test_rougeL': 13.9776,\n",
       " 'test_rougeLsum': 19.1916,\n",
       " 'test_gen_len': 97.0,\n",
       " 'test_runtime': 58.9905,\n",
       " 'test_samples_per_second': 0.051,\n",
       " 'test_steps_per_second': 0.017}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a97d1514",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Article Bias: center, Summary Bias: left\n",
      "Input: U.S. House condemns 'QAnon' conspiracy theory; 17 Republicans vote no\n",
      "WASHINGTON (Reuters) - The U.S. House of Representatives on Friday voted to condemn the online pro-Trump conspiracy theory known as \"QAnon,\" but 17 Republicans opposed the non-binding resolution, whose sponsor Democrat Representative Tom Malinowski said he has received death threats.\n",
      "The House voted 371-18 to reject the conspiracy theory, which posits President Donald Trump has been working to take down a global child sex ring. As many as a dozen Republican candidates for Congress have voiced some support for the theory, and at least one of them appears to be a on a path to victory.\n",
      "\"The grotesque nature of the tweets and Instagram posts and the anti-Semitic tripe spewed by QAnon adherents should cause concern for everyone,\" Representative Denver Riggleman, a Republican co-sponsor of the resolution, said on the House floor.\n",
      "\"But the death threats Tom Malinowski received were at surprise and a shock,\" Riggleman said. \"This type of behavior is easily condemned.\"\n",
      "Seventeen Republicans lawmakers and independent Representative Justin Amash voted against the resolution. Another Republican voted present, and forty lawmakers, most of them Republicans, did not vote.\n",
      "Writing on Twitter, Amash said the resolution threatened protected speech - and may make things worse. \"These are conspiracy theorists who believe in a deep state that's fighting against them,\" he wrote.\n",
      "Republican candidates who have voiced some measure of support for the QAnon theory include Georgia businesswoman Marjorie Taylor Greene, on track for a House seat after her Democratic opponent dropped out, and Jo Rae Perkins, who is running for Senate in Oregon against incumbent Senator Jeff Merkley. He is expected to win.\n",
      "The theory claims without evidence that \"deep-state\" traitors, child sex predators and prominent Democrats are plotting against Trump, who in turn is leading a plot against them. The FBI included QAnon last year in a warning about \"conspiracy theory-driven domestic extremists.\"\n",
      "\n",
      "Target Summary: QAnon, a conspiracy theory claiming that Donald Trump is fighting against nefarious forces, was condemned by a resolution in the House, but not unanimously. Some Republicans, including Reps. Jodey Arrington, Michael Burgess, Bill Flores, and Brian Babin of Texas; Rob Bishop of Utah; Mo Brooks of Alabama; Buddy Carter and Drew Ferguson of Georgia; Warren Davidson of Ohio; Jeff Duncan and Ralph Norman of South Carolina; Paul Gosar of Arizona; Mike Kelly and Scott Perry of Pennsylvania; Tom Tiffany of Wisconsin; Daniel Webster of Florida; and Steve King of Iowa, voted against it or did not vote at all. QAnon has been classified as a domestic-terror threat by the FBI for its threatening behavior towards those who do not believe this theory, and one of its followers will soon be elected to Congress. Despite having received bipartisan support, the resolution was not supported by all members of the House.\n",
      "\n",
      "\n",
      "Predicted Summary: U.S. House of Representatives voted 371-18 to reject the conspiracy theory, which posits President Donald Trump has been working to take down a global child sex ring. As many as a dozen Republican candidates for Congress have voiced some support for the theory, and at least one of them appears to be a on a path to victory.\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Example 2:\n",
      "Article Bias: left, Summary Bias: left\n",
      "Input: Why did some Republicans balk at a resolution condemning QAnon?\n",
      "As many Americans came to realize in recent months, QAnon is a crackpot conspiracy theory that says Donald Trump is secretly at war with nefarious forces of evil, including Democrats, Hollywood celebrities, the \"deep state,\" cannibals, and an underground ring of Satanic pedophiles. As we've discussed, this isn't just the usual conspiratorial nonsense bubbling up from the right; it's vastly weirder, more radical, and more dangerous.\n",
      "Last year, the FBI went so far as to classify QAnon as a domestic-terror threat in an internal memo. As recently as July, the West Point Combating Terrorism Center published a study characterizing QAnon as a burgeoning threat to public safety.\n",
      "The delusional nonsense has become more politically relevant of late, in part because at least one of its adherents will soon be elected to Congress, in part because of the president's deeply unfortunate rhetoric on the matter, and in part because a House Democrat this week started receiving death threats from QAnon followers.\n",
      "It's against this backdrop that the House today decided to vote on a bipartisan resolution condemning the crackpot conspiracy theory. NPR reported:\n",
      "The House overwhelmingly approved a resolution condemning QAnon, the fringe movement that promotes wide-ranging conspiracies about the U.S. government and yet has enjoyed a rising tide inside conservative politics in part because of tacit encouragement from President Trump.\n",
      "At first blush, the fact that this resolution was easily approved may seem like a small victory for common sense, but the roll call highlights a nagging detail: the measure didn't pass unanimously.\n",
      "In fact, 17 House Republicans voted against it; one House Republican voted \"present,\" and 34 House Republicans didn't vote on the resolution at all.\n",
      "The Republicans who voted against the anti-QAnon resolution are Reps. Jodey Arrington, Michael Burgess, Bill Flores, and Brian Babin of Texas; Rob Bishop of Utah; Mo Brooks of Alabama; Buddy Carter and Drew Ferguson of Georgia; Warren Davidson of Ohio; Jeff Duncan and Ralph Norman of South Carolina; Paul Gosar of Arizona; Mike Kelly and Scott Perry of Pennsylvania; Tom Tiffany of Wisconsin; Daniel Webster of Florida; and Steve King of Iowa.\n",
      "So, on the one hand, it's good that most GOP lawmakers voted for the bipartisan measure. On the other hand, about a fourth of the House Republican conference didn't vote for it.\n",
      "\n",
      "Target Summary: QAnon, a conspiracy theory claiming that Donald Trump is fighting against nefarious forces, was condemned by a resolution in the House, but not unanimously. Some Republicans, including Reps. Jodey Arrington, Michael Burgess, Bill Flores, and Brian Babin of Texas; Rob Bishop of Utah; Mo Brooks of Alabama; Buddy Carter and Drew Ferguson of Georgia; Warren Davidson of Ohio; Jeff Duncan and Ralph Norman of South Carolina; Paul Gosar of Arizona; Mike Kelly and Scott Perry of Pennsylvania; Tom Tiffany of Wisconsin; Daniel Webster of Florida; and Steve King of Iowa, voted against it or did not vote at all. QAnon has been classified as a domestic-terror threat by the FBI for its threatening behavior towards those who do not believe this theory, and one of its followers will soon be elected to Congress. Despite having received bipartisan support, the resolution was not supported by all members of the House.\n",
      "\n",
      "\n",
      "Predicted Summary: The House of Representatives passed a resolution condemning QAnon, a conspiracy theory that claims Donald Trump is secretly at war with nefarious forces of evil, including Democrats, Hollywood celebrities, the \"deep state,\" cannibals, and an underground ring of Satanic pedophiles. However, 17 House Republicans voted against it; one House Republican voted \"present,\" and 34 House Republicans didn't vote on the resolution at all. The FBI went so far as to classify Q anon as a domestic-terror threat in an internal memo, and as recently as July, the West Point Combating Terrorism Center published a study characterizing it as a burgeoning threat to public safety.\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Example 3:\n",
      "Article Bias: right, Summary Bias: left\n",
      "Input: Seventeen Republican congressmen and Justin Amash vote against House resolution condemning QAnon\n",
      "Rep. Buddy Carter of Georgia was one of those who voted nay but later explained on Twitter that he did so unintentionally and instead meant to vote yea.\n",
      "In addition to the 17, 33 Republican members of Congress abstained.\n",
      "Not all of those who voted no have publicly explained why.\n",
      "\"The resolution threatens protected speech (absurd as that speech may be), and its prescriptions for addressing QAnon aren't appropriate for what we know about them & may make things worse. These are conspiracy theorists who believe in a deep state that's fighting against them,\" Amash wrote on Twitter.\n",
      "\"In the middle of a global pandemic, while our cities are subjected to violence and hardworking Americans are watching their livelihoods be burnt to the ground by rioting leftist groups,\" Florida Rep. Daniel Webster told the Washington Examiner, \"Democrats in Congress are giving legitimacy to fringe groups that peddle in conspiracy theories. I never thought I'd live to see this day - instead of passing a bill to renew the Paycheck Protection Program or condemning rioting, looting, and violence against law-abiding citizens, Democrats are railing against an internet group.\"\n",
      "Rep. Brian Babin expressed a similar desire to not give QAnon any legitimacy.\n",
      "\"I know next to nothing about this QAnon stuff, but I do know that this resolution put forward by the House Democrat majority will serve only to give its devotees the publicity and legitimacy they are desperate for,\" he told the Washington Examiner. \"We've got big, real issues to deal with in Congress, and instead, we spent most of today debating this silly, pointless, powerless resolution that was written and brought to the floor for one reason: to make campaign commercials. I didn't want to offer any more undeserved legitimacy to either QAnon or these political games so I did my part: I voted no.\"\n",
      "Rep. Ralph Norman of South Carolina said in a statement that while he condemned \"in the strongest terms QAnon, Antifa, KKK,\" the resolution \"was yet another worthless messaging bill that does absolutely nothing to address the violence taking place in cities throughout our nation.\"\n",
      "He added: \"For Congress to pass a resolution condemning QAnon by name, but make no such mention of other violent organizations, is shameful.\"\n",
      "Others who voted against the resolution included Reps. Jodey Arrington of Texas, Rob Bishop of Utah, Mo Brooks of Alabama, Michael Burgess of Texas, Warren Davidson of Ohio, Jeff Duncan of South Carolina, Drew Ferguson of Georgia, Bill Flores of Texas, Paul Gosar of Arizona, Steve King of Iowa, Mike Kelly of Pennsylvania, Scott Perry of Pennsylvania, and Thomas Tiffany of Wisconsin.\n",
      "In response to this report, Arrington said the resolution was an attempt by Democrats to downplay the actions of \"radical Leftist groups\" like antifa.\n",
      "\"There is a world of difference between conspiracy and criminal - one is protected by the First Amendment; the other should be condemned in all forms. It's a swampy strategy to call out a fringe right-wing group with no mention of ANTIFA and other radical Leftist groups after over one hundred days of unmitigated mob violence in cities across America,\" Arrington said in a statement. \"Instead of political stunts, Democrat leadership should be working on bipartisan legislation to provide relief to working families and small businesses in a time of unprecedented crisis.\"\n",
      "President Trump came under fire weeks ago after he avoided directly condemning QAnon. Trump also endorsed Marjorie Taylor Greene, who is running for Congress in Georgia and has voiced support for the conspiracy theory.\n",
      "The Washington Examiner contacted the offices of the remaining congressmen who voted nay for comment but did not hear back.\n",
      "Anthony Leonardi contributed to this report.\n",
      "\n",
      "Target Summary: QAnon, a conspiracy theory claiming that Donald Trump is fighting against nefarious forces, was condemned by a resolution in the House, but not unanimously. Some Republicans, including Reps. Jodey Arrington, Michael Burgess, Bill Flores, and Brian Babin of Texas; Rob Bishop of Utah; Mo Brooks of Alabama; Buddy Carter and Drew Ferguson of Georgia; Warren Davidson of Ohio; Jeff Duncan and Ralph Norman of South Carolina; Paul Gosar of Arizona; Mike Kelly and Scott Perry of Pennsylvania; Tom Tiffany of Wisconsin; Daniel Webster of Florida; and Steve King of Iowa, voted against it or did not vote at all. QAnon has been classified as a domestic-terror threat by the FBI for its threatening behavior towards those who do not believe this theory, and one of its followers will soon be elected to Congress. Despite having received bipartisan support, the resolution was not supported by all members of the House.\n",
      "\n",
      "\n",
      "Predicted Summary: 17 Republican congressmen and Justin Amash vote against House resolution condemning QAnon. Rep. Carter of Georgia was one of those who voted nay but later explained on Twitter that he did so unintentionally and instead meant to vote yea. The resolution threatens protected speech and may make things worse, Rep. Amash wrote on Twitter. Not all members of Congress who voted no have publicly explained why.\n",
      "\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "predicted_texts = [tokenizer.decode(token_ids, skip_special_tokens=True) for token_ids in preds2.predictions]\n",
    "\n",
    "# Show a few example outputs\n",
    "for i in range(len(predicted_texts)):  # Just show the first 5 examples\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Article Bias: {test[i]['article_bias']}, Summary Bias: {test[i]['summary_bias']}\")\n",
    "    print(f\"Input: {test[i]['article']}\")\n",
    "    print()\n",
    "    print(f\"Target Summary: {test[i]['summary']}\")\n",
    "    print()\n",
    "    print(f\"Predicted Summary: {predicted_texts[i]}\\n\")\n",
    "    print()\n",
    "    print('*' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c0a27ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: summary, id, summary_bias, article, article_bias. If summary, id, summary_bias, article, article_bias are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 581\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "735080e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.22916316986083984,\n",
       " 'test_rouge1': 90.1272,\n",
       " 'test_rouge2': 85.6914,\n",
       " 'test_rougeL': 87.6164,\n",
       " 'test_rougeLsum': 89.4535,\n",
       " 'test_gen_len': 123.9088,\n",
       " 'test_runtime': 764.4302,\n",
       " 'test_samples_per_second': 0.76,\n",
       " 'test_steps_per_second': 0.191}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343cc58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
